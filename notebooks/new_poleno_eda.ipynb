{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ee2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall --no-cache-dir \"numpy<2\" scipy seaborn matplotlib pandas pyarrow\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "df = pd.read_csv(\"./data/final/poleno/poleno_labels_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d915d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_counts = df.value_counts([\"genus\", \"species\", \"dataset_id\"]).reset_index()\n",
    "# sample_counts.to_excel(\"available_dataset_ids.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18edfab",
   "metadata": {},
   "source": [
    "Drop samples with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad842b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = df[df.isnull().any(axis=1)]\n",
    "null_rows[\"dataset_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ed045",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before_dropna = len(df)\n",
    "df = df.dropna()\n",
    "print(f\"Samples in original dataset: {len_before_dropna}\\nDropping samples with nan : {len_before_dropna-len(df)}\\nLength after dropping : {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f43f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"dataset_id\", \"species\", \"genus\"]\n",
    "\n",
    "for col in columns:\n",
    "    print(f\"Nr unique {col:<{max(len(c) for c in columns)}} : {len(df[col].value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bf5c1",
   "metadata": {},
   "source": [
    "#### Number of images per event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_event_id = df[\"event_id\"].value_counts()\n",
    "valid_samples_per_event_id = samples_per_event_id[samples_per_event_id == 2].index\n",
    "samples_per_event_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c0e15",
   "metadata": {},
   "source": [
    "Drop columns with more then two samples per `event_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"event_id\"].isin(valid_samples_per_event_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396058c",
   "metadata": {},
   "source": [
    "Drop columns that dont have exacly one image_nr 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = (\n",
    "    df.groupby('event_id')['image_nr']\n",
    "      .apply(lambda x: (x == 0).sum() == 1 and \n",
    "                       (x == 1).sum() == 1)\n",
    ")\n",
    "len_before_filtering = len(df)\n",
    "df = df[df['event_id'].isin(valid_ids[valid_ids].index)]\n",
    "\n",
    "print(len(df) - len_before_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_per_label(df, column=\"species\", min_count=2000, highlight_column=None, highlight_labels=None):\n",
    "\n",
    "    highlight_column = column if highlight_column is None else highlight_column\n",
    "\n",
    "    sample_columns = list(set([column, highlight_column ]))\n",
    "\n",
    "    samples_per_label = df.value_counts(sample_columns).reset_index()\n",
    "\n",
    "    # Create color list (default all blue)\n",
    "    colors = [\"skyblue\"] * len(samples_per_label)\n",
    "\n",
    "\n",
    "    if highlight_labels:\n",
    "        highlight_set = set(highlight_labels)\n",
    "        colors = [\n",
    "            \"orange\" if label in highlight_set else \"skyblue\"\n",
    "            for label in samples_per_label[highlight_column]\n",
    "        ]\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.bar(x=samples_per_label[column], height=samples_per_label[\"count\"], color=colors)\n",
    "    plt.axhline(min_count, color='red', ls='dotted')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"NR of samples for \")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99054ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df.value_counts(\"genus\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce46f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_labels = [\"Acer\", \"Phytophthora\", \"Chenopodium\", \"Platanus\", \"Holcus\", \"Cynosurus\", \"Anthoxanthum\"]\n",
    "show_images_per_label(df, column=\"genus\", min_count=10000, highlight_labels=highlight_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_per_label(df, column=\"species\", min_count=2000, highlight_column=\"genus\", highlight_labels=highlight_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb058c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_labels=[]\n",
    "show_images_per_label(df, column=\"dataset_id\", min_count=2000, highlight_labels=highlight_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"species\").value_counts([\"dataset_id\"]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bdf290",
   "metadata": {},
   "source": [
    "## Dataset Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1043c49",
   "metadata": {},
   "source": [
    "### Split into base, collection and zero dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, column, values):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into two parts based on matching values in a given column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame.\n",
    "    column : str\n",
    "        Column name to filter on (e.g., 'dataset_id', 'species', etc.).\n",
    "    values : list\n",
    "        List of values to select from the specified column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of (df_selected, df_remaining)\n",
    "        df_selected  -> rows where df[column] is in values\n",
    "        df_remaining -> all other rows\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        raise KeyError(f\"Column '{column}' not found in DataFrame.\")\n",
    "\n",
    "    if not isinstance(values, (list, tuple, set)):\n",
    "        raise TypeError(\"Parameter 'values' must be a list, tuple, or set.\")\n",
    "\n",
    "    mask = df[column].isin(values)\n",
    "    df_selected = df[mask].copy()\n",
    "    df_remaining = df[~mask].copy()\n",
    "\n",
    "    return df_selected, df_remaining\n",
    "\n",
    "\n",
    "isolate_species = ['Urtica sp. 1', 'Urtica sp. 1', 'Juniperus communis', 'Lolium rigidum',]\n",
    "\n",
    "isolate_dataset = [\"11eed16c-db23-b464-8bde-1e119433b62f\"]\n",
    "\n",
    "df_species_isolated, df_base = split_dataframe(df, column=\"species\", values=isolate_species)\n",
    "df_dataset_isolated, df_base = split_dataframe(df_base, column=\"dataset_id\", values=isolate_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed5309",
   "metadata": {},
   "source": [
    "### Split into train, val, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d82a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test_grouped(\n",
    "    df,\n",
    "    stratify_col,\n",
    "    group_col=\"event_id\",\n",
    "    test_size_per_class=50,\n",
    "    val_size_per_class=20,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into train, validation, and test sets while:\n",
    "    - keeping all rows from the same group (e.g., event_id) together,\n",
    "    - sampling a fixed number of groups per class for both test and validation sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataset.\n",
    "    stratify_col : str\n",
    "        Column used for stratification (e.g., 'species').\n",
    "    group_col : str, optional\n",
    "        Column that defines grouping (e.g., 'event_id').\n",
    "    test_size_per_class : int, optional\n",
    "        Number of groups (not rows) per class to assign to the test set.\n",
    "    val_size_per_class : int, optional\n",
    "        Number of groups (not rows) per class to assign to the validation set.\n",
    "    random_state : int, optional\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (df_train, df_val, df_test)\n",
    "        DataFrames with consistent event grouping.\n",
    "    \"\"\"\n",
    "\n",
    "    if stratify_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{stratify_col}' not found in DataFrame.\")\n",
    "    if group_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{group_col}' not found in DataFrame.\")\n",
    "\n",
    "    # Map each event to its class (species)\n",
    "    event_info = df[[group_col, stratify_col]].drop_duplicates(subset=group_col)\n",
    "\n",
    "    # Shuffle events to randomize selection\n",
    "    event_info = shuffle(event_info, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    test_events = []\n",
    "    val_events = []\n",
    "    train_events = []\n",
    "\n",
    "    # --- Fixed-size sampling per class for test and val ---\n",
    "    for label, group in event_info.groupby(stratify_col):\n",
    "        n = len(group)\n",
    "\n",
    "        # If too small, use whatever available\n",
    "        n_test = min(test_size_per_class, n)\n",
    "        test_part = group.sample(n=n_test, random_state=random_state)\n",
    "        remaining = group.drop(test_part.index)\n",
    "\n",
    "        n_val = min(val_size_per_class, len(remaining))\n",
    "        val_part = remaining.sample(n=n_val, random_state=random_state)\n",
    "        train_part = remaining.drop(val_part.index)\n",
    "\n",
    "        test_events.append(test_part)\n",
    "        val_events.append(val_part)\n",
    "        train_events.append(train_part)\n",
    "\n",
    "    # Combine event-level data\n",
    "    test_events = pd.concat(test_events)\n",
    "    val_events = pd.concat(val_events)\n",
    "    train_events = pd.concat(train_events)\n",
    "\n",
    "    # Map back to full rows (include all images per event)\n",
    "    df_test = df[df[group_col].isin(test_events[group_col])]\n",
    "    df_val = df[df[group_col].isin(val_events[group_col])]\n",
    "    df_train = df[df[group_col].isin(train_events[group_col])]\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd837c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_config = {\n",
    "    \"data\": df_base,\n",
    "    \"test_events_per_class\": 100,\n",
    "    \"val_events_per_class\": 100,\n",
    "}\n",
    "\n",
    "separate_species_config = {\n",
    "    \"data\": df_species_isolated,\n",
    "    \"test_events_per_class\": 100,\n",
    "    \"val_events_per_class\": 100,\n",
    "}\n",
    "\n",
    "separate_dataset_config = {\n",
    "    \"data\": df_dataset_isolated,\n",
    "    \"test_events_per_class\": 100,\n",
    "    \"val_events_per_class\": 100,\n",
    "}\n",
    "\n",
    "split_configs = [basic_config, separate_species_config, separate_dataset_config]\n",
    "\n",
    "for config in split_configs:\n",
    "\n",
    "    train_df, val_df, test_df = split_train_val_test_grouped(\n",
    "        df=config[\"data\"],\n",
    "        stratify_col=\"dataset_id\",\n",
    "        group_col=\"event_id\",\n",
    "        test_size_per_class=config[\"test_events_per_class\"],\n",
    "        val_size_per_class=config[\"val_events_per_class\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    print(\"Train events:\", train_df[\"event_id\"].nunique())\n",
    "    print(\"Val events:\", val_df[\"event_id\"].nunique())\n",
    "    print(\"Test events:\", test_df[\"event_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5520c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"dataset_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ee551",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[\"dataset_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3188037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"dataset_id\", \"species\"]].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
